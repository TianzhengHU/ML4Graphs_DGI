
Epoch: 0 Loss: 0.6931481957435608
Epoch: 1 Loss: 0.692886233329773
Epoch: 2 Loss: 0.6945438385009766
Epoch: 3 Loss: 0.6954991817474365
Epoch: 4 Loss: 0.6925548315048218
Epoch: 5 Loss: 0.6921600699424744
Epoch: 6 Loss: 0.6930434703826904
Epoch: 7 Loss: 0.6919063925743103
Epoch: 8 Loss: 0.6911975741386414
Epoch: 9 Loss: 0.6912192106246948
Epoch: 10 Loss: 0.6906331181526184
Epoch: 11 Loss: 0.6899095773696899
Epoch: 12 Loss: 0.6891462206840515
Epoch: 13 Loss: 0.6886089444160461
Epoch: 14 Loss: 0.6877198219299316
Epoch: 15 Loss: 0.6876838207244873
Epoch: 16 Loss: 0.6864469051361084
Epoch: 17 Loss: 0.6863601803779602
Epoch: 18 Loss: 0.6845493316650391
Epoch: 19 Loss: 0.6854472160339355
Epoch: 20 Loss: 0.6834532022476196
Epoch: 21 Loss: 0.6820924282073975
Epoch: 22 Loss: 0.6838467717170715
Epoch: 23 Loss: 0.6832255125045776
Epoch: 24 Loss: 0.680806040763855
Epoch: 25 Loss: 0.6814807057380676
Epoch: 26 Loss: 0.6813646554946899
Epoch: 27 Loss: 0.6795892715454102
Epoch: 28 Loss: 0.6817240715026855
Epoch: 29 Loss: 0.680087149143219
Epoch: 30 Loss: 0.6806408762931824
Epoch: 31 Loss: 0.6799230575561523
Epoch: 32 Loss: 0.6797049045562744
Traceback (most recent call last):
  File "/Users/hutianzheng/Desktop/studying/Y2-P3-ml4grpahs/DGI_CODE/ML4Graphs_DGI/main.py", line 83, in <module>
    loss.backward()
  File "/opt/anaconda3/envs/DeepL/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/opt/anaconda3/envs/DeepL/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
